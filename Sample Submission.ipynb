{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with io.open('train_data.json','r',encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        d = json.loads(line)\n",
    "        train_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with io.open('test_data.json','r',encoding='utf8') as f:\n",
    "    for line in f.readlines():\n",
    "        d = json.loads(line)\n",
    "        test_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "paragraph_ends = []\n",
    "i = 0\n",
    "for paragraph in train_data:\n",
    "    for sentence in paragraph['Sentences']:\n",
    "        s = re.findall(r\"\\w+|[^\\w\\s]\", sentence, re.UNICODE)\n",
    "        sentences.append(s)\n",
    "        i += len(s)\n",
    "    paragraph_ends.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "boundaries = set(paragraph_ends)\n",
    "offset = 0\n",
    "for sent in sentences:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def punct_features(tokens, i):\n",
    "    t1 = \"\"\n",
    "    t2 = \"\"\n",
    "    if i + 2 < len(tokens):\n",
    "        t1 = tokens[i + 2]\n",
    "    if i - 2 >= 0:\n",
    "        t2 = tokens[i - 2]\n",
    "    return {'next-word-capitalized': tokens[i + 1][0].isupper(),\n",
    "            #'prev-word-capitalized': tokens[i - 1][0].isupper(),\n",
    "            'prevword': tokens[i - 1],\n",
    "            'nextword': tokens[i + 1],\n",
    "#             'is_punct_prev' : tokens[i - 1] in ends,\n",
    "#             'is_punct_next' : tokens[i + 1] in ends,\n",
    "            #'is_punct_prev2' : t1 in ends,\n",
    "            #'is_punct_next2' : t2 in ends,\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i - 1]),\n",
    "            'next-word-is-one-char': len(tokens[i + 1])\n",
    "#             'prev-word-is-one-char2': len(t1),\n",
    "#             'next-word-is-one-char2': len(t2)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ends = [u'!', u'\"', u'…', u'.', u'»', u'?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "                   for i in range(len(tokens) - 1)\n",
    "                   if tokens[i] in ends]\n",
    "#  and i not in paragraph_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91810\n"
     ]
    }
   ],
   "source": [
    "print len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out_data = np.zeros((26476, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set = featuresets\n",
    "#train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "#nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for p in test_data:\n",
    "    par = p['Paragraph']\n",
    "    i = 0\n",
    "    p['Processed'] = []\n",
    "    for cand in p['Marks']:\n",
    "        words = re.findall(r\"\\w+|[^\\w\\s]\", par[i:cand['Pos'] + 1], re.UNICODE)\n",
    "        p['Processed'].extend(words)\n",
    "        cand['Word'] = len(p['Processed']) - 1\n",
    "        i = cand['Pos'] + 1\n",
    "            \n",
    "for p in test_data:\n",
    "    for cand in p['Marks']:\n",
    "        if cand['Word'] != len(p['Processed']) - 1:\n",
    "            feature = punct_features(p['Processed'], cand['Word'])\n",
    "            if classifier.classify(feature) == True:\n",
    "                out_data[cand['Index'] - 1] = 1\n",
    "            else:\n",
    "                out_data[cand['Index'] - 1] = 0\n",
    "        else:\n",
    "            out_data[cand['Index'] - 1] = 1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(out_data, columns=['Mark'], index=range(1,26477))\n",
    "df.index.name = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
